{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Linear Regression\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Correlation versus Correlation\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\n Back in my home country, and\nbefore the hippy movement changed our culture, kids, who were curious\nwhere the babies come from, were told that they are brought by the\nstork (a large bird, see Fig.[fig:storksa](#fig:storksa)). Storks were indeed a\ncommon sight in rural areas, and large enough to sell this story to a\n3-year-old.\n\n![img](Linear_Regression/Ringed_white_stork_2019-11-22_15-14-15.png \"The Stork. Image by Soloneying, from ![img](https://commons.wikimedia.org/wiki/File:Ringed_white_stork.jpg) Downloaded Nov 22<sup>nd</sup> 2019.\")\n\nTo bad, we are now grown up scientists with a penchant for critical\nthinking. Rather than believing this story, we want to see the data, and ask\nif this were true, we should see a good correlation between the number of storks\nand the number of babies. Low and behold, these two variables, actually\ncorrelate in a statistically significant way, i.e, the more storks we count in\na country, the higher the (human) birthrate. Since both variables increase\ntogether, this is called a positive correlation. See Fig. [4](#org2a3ebcf)\n\n![img](storks.png \"The birthrate and the number of stork pairs correlate in a statistical significant way. This analysis suggest that each stork pair delivers about 29 human babies, and that about 225 thousand babies were born otherwise. Data after <sup id=\"33933dcd3d4eb462061d758c913e8daa\"><a href=\"#matthews-2000-stork-devil\" title=\"Robert Matthews, Storks Devilver Babies (p = 0.008), {Teaching Statistics}, v(2), 36--38 (2000).\">matthews-2000-stork-devil</a></sup>.\")\n\nNow, does this prove that the storks deliver the babies? Obviously (or so we\nthink) not. Just because two observable quantities correlate, does in no way\nimply that one is the cause of the other. The more likely explanation is that\nboth variables are affected by a common process (i.e., industrialization).\n\nIt is a common mistake to confuse correlation with causation. Another\ngood example is to correlate drinking with heart attacks. This surely\nwill correlate but the story is more difficult. Are there e.g.,\npatterns like drinkers tend to do less exercise than non-drinkers? So\neven if you have a good hypothesis why two variables are correlated,\nthe correlation on its own, proves nothing.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### Understanding the results of a linear regression analysis\n\n"]},{"cell_type":"markdown","metadata":{},"source":["\nRegression analysis compares how well a dataset of two variables (lets\ncall them `x` and `y`) can be described by a function which allows us\nto predict the value of the dependent variable `y` based on the value\nof the independent variable `x`.  In the case of a linear regression,\nthis can be expressed by a linear equation:\n\n\\begin{equation}\n\\label{eq:1}\ny = a+mx\n\\end{equation}\n\nwhere `a` denotes the y-axis intercept, `m` denotes the slope. Note\nthat the above equation is a simple model, which we can use to make\npredictions about actual data. Linear regression analysis adjusts the\nparameters `a` and `m` in such a way that the difference between the\nmeasured data and the model prediction is minimized.\n\nFrom a user perspective, we are interested to understand how good the\nmodel actually is. and how to interpret the key indicators of a given\nregression model:\n\n-   **r<sup>2</sup>:** or coefficient of determination. \\index{linear\n    regression!rsquare} \\index{linear regression!coefficient of\n    determination} This value is in the range from zero to one and\n    expresses how much of the observed variance \\index{linear\n    regression!variance} in the data is explained by the regression\n    model. So a value of 0.7 indicates that 70% of the variance is\n    explained by the model, and that 30% of the variance is explained\n    by other processes which are not captured by the linear model\n    (e.g., measurements errors, or some non-linear effect affecting `x`\n    and `y`). In Fig. [BROKEN LINK: fig:storks] 38% of the variance in the birthrate\n    can be explained by the increase in stork pairs.  Note that often\n    you will also find the term R<sup>2</sup>. For a simple linear regression with\n    two variables, r<sup>2</sup> equals R<sup>2</sup>. However, if your model incorporates\n    more than 2 variables, these numbers can be different.\n-   **p:** When you do a linear regression, you basically state the\n    hypothesis that `y` depends `x` and that they are linked by a\n    linear equation. If you test a hypothesis, you however also have to\n    test the so called **null-hypothesis**, which in this case would\n    \\index{linear regression!null hypothesis} state that `y` is\n    \\index{linear regression!p-value} unrelated to `x`. The p-value\n    expresses the likelihood that the null-hypothesis is true. So a\n    p-value of 0.1 indicates a 10% chance that your data does not\n    correlate. A p-value of 0.01, indicates a 1% chance that your data\n    is not correlated. Typically, we can reject the null-hypothesis if\n    `p < 0.05`, in other words, we are 95% sure the null hypothesis is\n    wrong. In Fig. [BROKEN LINK: fig:storks], we are 99.2% sure the null hypothesis is\n    wrong. Note that there is not always a simple relationship between\n    r<sup>2</sup> and p.\n\n"]},{"cell_type":"markdown","metadata":{},"source":["### The statsmodel library\n\n"]},{"cell_type":"markdown","metadata":{},"source":[" \nPythons success rests to a considerable degree on the myriad of third\nparty libraries which, unlike matlab, are typically free to use. In\nthe following we will use the \"statsmodel\" library, but there are\nplenty of other statistical libraries we could use as well. \n\nThe statsmodel library provides different interfaces. Here we will use\nthe formula interface which is similar to the R-formula\nsyntax. However not all statsmodel functions are available through\nthis interface (yet?). First we import the needed libraries:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd  # import pandas as pd\nimport os  # no need to set an alias, since os is already short\nimport statsmodels.formula.api as smf \n\n# define the file and sheetname we want to read. Note that the file\n# has to be present in the local working directory!\nfn: str = \"storks_vs_birth_rate.csv\"  # file name\n\n# this little piece of code could have saved me 20 minutes\nif not os.path.exists(fn):  # check if the file is actually there\n    raise FileNotFoundError(f\"Cannot find file {fn}\")\n\ndf :pd.DataFrame = pd.read_csv(fn)  # read data\ndf.columns = [\"Babies\", \"Storks\"] # replace colum names\ndf.head() # test that all went well"]},{"cell_type":"markdown","metadata":{},"source":["For the statistical analysis, we want to analyze whether the number of\nstorks predicts the number of babies. In other words does the birth\nrate depend on the number of storks? For this, we need to define a\nstatistical model, and test whether the model predictions will fit the\ndata:\n\n-   The gory details of this procedure are beyond the scope of this\n    course - if you have not yet taken a stats class, I do recommend\n    doing so!\n-   There are many ways of doing this. Here we use an approach which\n    is common in `R`\n\nYou may notice that the type hints below (and also above), appear a\nbit superfluous here. After all, you are really just duplicating the\nobvious. However, once your code becomes longer, it will no longer be\nobvious, so I keep the type hinting here to encourage good habits.\n\nIn the below code, `smf` is the alias for the statistics library, and\n`ols` stands for \"ordinary least squares\". The first line thus creates\nour model-object (aptly named \"model\"). We specify this object by\nproviding the formula `\"Babies ~ Storks` which states that in our\nmodel the number of Babies should depend on the number of\nstorks. These names must correspond to the variable names in the\ndataframe `df`. Line #2 is used to create fit between our linear\nregression model and the data. The results of this fit will be stored\nthe `model.fit` object (i.e., \"results\"). Line 3 invokes the\n`summary()` method of the results object.\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["model :smf.ols = smf.ols(formula=\"Babies ~ Storks\",data=df)\nresults :model.fit = model.fit()      # fit the model to the data\nprint(results.summary())   # print the results of the analysis"]},{"cell_type":"markdown","metadata":{},"source":["Plenty of information here, probably more than the you asked for. But\nnote the first line, which states that 'Babies' is the dependent\nvariable. This is useful and will help you to catch errors in your\nmodel definition. There are also a couple of warnings, indicating that\nyour data quality may be less than excellent.\n\nIf you compare the output with Figure [fig:storks](#fig:storks), you can see that\nr<sup>2</sup> value is called \"R-squared\", the p-value is called \"Prob\n(F-statistic)\", the y-intercept is the first value in the \"Intercept\"\nrow, the slope is the first value in the \"Storks\" row.You can also\nextract these parameters from the model results object like this:\n\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# retrieve values from the model results\nslope   :float = results.params[1]  # the slope\ny0      :float = results.params[0]  # the y-intercept\nrsquare :float = results.rsquared   # rsquare\npvalue  :float = results.pvalues[1] # the pvalue"]},{"cell_type":"markdown","metadata":{},"source":["Using these parameters, you now calculate the regression line shown in\nFigure [fig:storks](#fig:storks) and plot in into the data. We will explore how\nto create the confidence interval in the next module.\n\n"]}],"metadata":{"org":null,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}